import JuMP, Gurobi; GRB_ENV = Gurobi.Env();
import JuMP.value as ƒ±
import LinearAlgebra.‚ãÖ as ‚ãÖ
import LinearAlgebra.norm as norm
import Random

function is_binary_bold(x) return abs(.5 - x) > (.5 - 5e-12) end; # a bold version of `is_binary`
function prev(t, d, T)
    n = t - d
    return n < 1 ? T+n : n
end; function gen_a_D_house(ID, DÀàUB) return (
    ID = ID,
    D = rand(0:DÀàUB, T), # base demand
    P_BUS = rand(12:24), # unidirectional due to no renewables
    P_EV = [2, rand(3:7)], # MIN and MAX charging power
    E_EV = rand(10:39),
    DW = rand(1:4, rand(2:5)), # cycle vector   
) end; function gen_a_G_house(ID) return (
    ID = ID,
    G = rand(0:15, T), # üåû renewables generation
    D = rand(2:9, T), # base demand
    P_BUS = rand(12:14), # bidirectional due to üåû
    P_EV = [2, rand(3:10)], # MIN and MAX charging power
    E_EV = rand(10:39),
    DW = rand(1:7, rand(2:7)), # cycle vector
) end; function find_a_frac_block(œá)
    for j = Random.shuffle(1:J)
        ks = haskey(œá[j], :bLent) ? [:bLent, :bEV, :bDW] : [:bEV, :bDW]
        for k = ks, x = œá[j][k]
            is_binary_bold(ƒ±(x)) || return j # [early return]
        end
    end; return 0 # all solutions are now agreeably integer
end; function solve_restricted_primal(B; mip = false)
    model = JuMP.Model(() -> Gurobi.Optimizer(GRB_ENV)); # restricted primal
    if mip
        JuMP.set_attribute(model, "MIPGap", 0)
        JuMP.set_attribute(model, "MIPGapAbs", 0)
    else
        JuMP.set_silent(model) # This is an LP, used to generate fractional trial solutions
    end
    JuMP.@variable(model, Œª[j = 1:J, v = 1:length(B[j][:p])] ‚â• 0); JuMP.@constraint(model, [j = 1:J], sum(Œª[j, :]) == 1);
    œá = NamedTuple[(; (k => similar(v, JuMP.VariableRef) for (k, v) = pairs(first(keys(B[j][:p]))))...) for j = 1:J]; # The "mean" vector
    for j = 1:J, k = keys(œá[j]), i = eachindex(œá[j][k])
        œá[j][k][i] = scalar_mean = JuMP.@variable(model)
        JuMP.@constraint(model, scalar_mean == sum(Œª[j, v]nt[k][i] for (v, nt) = enumerate(keys(B[j][:p]))))
        mip || continue
        k ‚àà [:bLent, :bEV, :bDW] && JuMP.set_integer(scalar_mean)
    end
    JuMP.@expression(model, pAgr[t = 1:T], sum(haskey(œá[j], :pBus) ? œá[j][:pBus][t] : œá[j][:pBus1][t]+œá[j][:pBus2][t] for j = 1:J));
    JuMP.@constraint(model, Œ≤[t = 1:T], P_AGR ‚â• pAgr[t]); # üü° linking constr
    # ‚ö†Ô∏è we do not explicitly enforce the "no reverse flow" constraint, but will test it post-optimizing
    JuMP.@objective(model, Min, MarketPrice ‚ãÖ pAgr);
    JuMP.optimize!(model); JuMP.assert_is_solved_and_feasible(model; allow_local = false)
    return œá
end; function initialize_inn(D)
    inn = Vector{JuMP.Model}(undef, J); # the intrablock MIP subproblems
    for (j, block) = enumerate(D)
        model = JuMP.Model(() -> Gurobi.Optimizer(GRB_ENV)) # MIP of the j-th block
        JuMP.set_silent(model)
        JuMP.set_attribute(model, "Threads", 1)
        JuMP.set_attribute(model, "TimeLimit", 3)
        JuMP.set_attribute(model, "MIPGap", 0)
        JuMP.set_attribute(model, "MIPGapAbs", 0)
        if length(block) == 2 # [pBus1; pBus2; pLent; vec(pEV); bLent; vec(bEV); vec(bDW)]
            h1, h2 = block
            JuMP.@variable(model, bLent[1:T], Bin) # 0 is lending
            JuMP.@variable(model, pLent[1:T])
            JuMP.@constraint(model, [t = 1:T], pLent[t] ‚â§ (1 - bLent[t])h1[:P_EV][end])
            JuMP.@constraint(model, [t = 1:T], (1 - bLent[t])h1[:P_EV][begin] ‚â§ pLent[t])
            JuMP.@variable(model, bEV[1:T, 1:2], Bin)
            JuMP.@variable(model, pEV[1:T, 1:2])
            JuMP.@constraint(model, [t = 1:T, h = 1:2], pEV[t, h] ‚â§ bEV[t, h]block[h][:P_EV][end])
            JuMP.@constraint(model, [t = 1:T, h = 1:2], bEV[t, h]block[h][:P_EV][begin] ‚â§ pEV[t, h])
            JuMP.@constraint(model, [t = 1:T, h = 1:2], bEV[t, h] ‚â§ bLent[t])
            JuMP.@constraint(model, sum(        view(pEV, :, 1)) ‚â• h1[:E_EV])
            JuMP.@constraint(model, sum(pLent + view(pEV, :, 2)) ‚â• h2[:E_EV])
            JuMP.@variable(model, bDW[1:T, 1:2], Bin)
            JuMP.@expression(model, pDW[t = 1:T, h = 1:2], sum(bDW[prev(t, œÜ-1, T), h]P for (œÜ, P) = enumerate(block[h][:DW])))
            JuMP.@constraint(model, [h = 1:2], sum(view(bDW, :, h)) ‚â• true)
            JuMP.@variable(model, -h1[:P_BUS] ‚â§ pBus1[1:T] ‚â§ h1[:P_BUS]) # üü°
            JuMP.@variable(model, false ‚â§ pBus2[1:T] ‚â§ h2[:P_BUS]) # üü°
            JuMP.@constraint(model, pBus1 + h1[:G] ‚â• pLent + h1[:D] + view(pEV, :, 1) + view(pDW, :, 1))
            JuMP.@constraint(model, pBus2          ‚â•         h2[:D] + view(pEV, :, 2) + view(pDW, :, 2))
            JuMP.@expression(model, prim_obj, MarketPrice ‚ãÖ (pBus1 + pBus2)) # the additional penalty is merely Œ≤-coefficiented
        elseif length(block) == 1 # [pBus; pEV; bEV; bDW]
            h = block[1]
            JuMP.@variable(model, bEV[1:T], Bin)
            JuMP.@variable(model, pEV[1:T])
            JuMP.@constraint(model, [t = 1:T], pEV[t] ‚â§ bEV[t]h[:P_EV][end])
            JuMP.@constraint(model, [t = 1:T], bEV[t]h[:P_EV][begin] ‚â§ pEV[t])
            JuMP.@constraint(model, sum(pEV) ‚â• h[:E_EV])
            JuMP.@variable(model, bDW[1:T], Bin)
            JuMP.@expression(model, pDW[t = 1:T], sum(bDW[prev(t, œÜ-1, T)]P for (œÜ, P) = enumerate(h[:DW])))
            JuMP.@constraint(model, sum(bDW) ‚â• true)
            JuMP.@variable(model, false ‚â§ pBus[1:T] ‚â§ h[:P_BUS]) # üü°
            JuMP.@constraint(model, pBus ‚â• h[:D] + pEV + pDW)
            JuMP.@expression(model, prim_obj, MarketPrice ‚ãÖ pBus) # the additional penalty is merely Œ≤-coefficiented
        end; inn[j] = model # save
    end # not include: penalty objective, non-block linking constr
    return inn
end; function initialize_out(an_UB) # an_UB ‚ö†Ô∏è should be valid
    model = JuMP.Model(() -> Gurobi.Optimizer(GRB_ENV)) # outer in DantzigWolfe decomposition
    JuMP.set_silent(model)
    JuMP.@variable(model, Œ≤[1:T] ‚â• 0) # multiplier vector of the üü° linking constr
    JuMP.@variable(model, Œ∏[1:J]) # This is a concise formulation---we omit the `pi` variable
    JuMP.@expression(model, common, -sum(Œ≤)P_AGR)
    JuMP.@expression(model, out_obj_tbMax, common + sum(Œ∏))
    JuMP.@objective(model, Max, out_obj_tbMax)
    JuMP.@constraint(model, out_obj_tbMax ‚â§ an_UB)
    return model, Œ∏, Œ≤
end; function reset_mj_obj!(mj, Œí)
    ( haskey(mj, :pBus) ? 
      JuMP.@objective(mj, Min, mj[:prim_obj] + Œí ‚ãÖ mj[:pBus]) :
      JuMP.@objective(mj, Min, mj[:prim_obj] + Œí ‚ãÖ (mj[:pBus1] + mj[:pBus2])) )
end; function build_con(j, mj, Œ∏, Œ≤)
    haskey(mj, :pBus) && return JuMP.@build_constraint(Œ∏[j] ‚â§ ƒ±(mj[:prim_obj]) + Œ≤ ‚ãÖ ƒ±.(mj[:pBus]))
    return JuMP.@build_constraint(Œ∏[j] ‚â§ ƒ±(mj[:prim_obj]) + Œ≤ ‚ãÖ (ƒ±.(mj[:pBus1]) + ƒ±.(mj[:pBus2])))
end; function get_full_vec(nt)
    haskey(nt, :pBus) && return [nt[:pBus]; nt[:pEV]; nt[:bEV]; nt[:bDW]]
    return [nt[:pBus1]; nt[:pBus2]; nt[:pLent]; vec(nt[:pEV]); nt[:bLent]; vec(nt[:bEV]); vec(nt[:bDW])]
end; function get_bool_part_vec(nt)
    haskey(nt, :bLent) && return [nt[:bLent]; vec(nt[:bEV]); vec(nt[:bDW])]
    return [nt[:bEV]; nt[:bDW]]
end; function get_full_num_tuple(nt)
    haskey(nt, :pBus) && return (
        pBus = ƒ±.(nt[:pBus]),
        pEV = ƒ±.(nt[:pEV]),
        bEV = round.(Bool, ƒ±.(nt[:bEV])),
        bDW = round.(Bool, ƒ±.(nt[:bDW])) )
    return (
        pBus1 = ƒ±.(nt[:pBus1]),
        pBus2 = ƒ±.(nt[:pBus2]),
        pLent = ƒ±.(nt[:pLent]),
        pEV = ƒ±.(nt[:pEV]),
        bLent = round.(Bool, ƒ±.(nt[:bLent])),
        bEV = round.(Bool, ƒ±.(nt[:bEV])),
        bDW = round.(Bool, ƒ±.(nt[:bDW]))
    )
end; function parallel_CG!(B, model, Œ∏, Œ≤)
    for ite = 1:typemax(Int)
        JuMP.optimize!(model); JuMP.assert_is_solved_and_feasible(model; allow_local = false, dual = true)
        @info "ite = $ite, bound is $(JuMP.objective_bound(model))"
        Œí = ƒ±.(Œ≤) # ‚úÇÔ∏è
        out_upd_vec .= false
        Threads.@threads for j = 1:J
            Œò_j = ƒ±(Œ∏[j]); mj = inn[j] # ‚úÇÔ∏è
            reset_mj_obj!(mj, Œí)
            JuMP.optimize!(mj); JuMP.assert_is_solved_and_feasible(mj; allow_local = false)
            Œî = Œò_j - JuMP.objective_value(mj)
            if Œî > 1e-11
                @info "Œî = $Œî, at j = $j"
                local intFullvertex = get_full_num_tuple(mj)
                if !haskey(B[j][:p], intFullvertex)
                    local con = build_con(j, mj, Œ∏, Œ≤)
                    local cut = @lock my_lock JuMP.add_constraint(model, con)
                    B[j][:p][intFullvertex] = cut
                    B[j][:d][cut] = intFullvertex
                    out_upd_vec[j] = true
                end
            end
        end
        any(out_upd_vec) && continue
        break
    end
end; function condense!(B, model) # ‚ö†Ô∏èüî¥ This post-procedure could be harmful
    # e.g. lose the chance to recover a integer-feasible primal solution
    # or, even if you can recover one, its quality is inferior than the one
    # recovered were this post-procedure unexecuted
    for j = 1:J, (cut, vertex) = collect(B[j][:d]) # üö∞ condensing
        JuMP.dual(cut) == 0 || continue
        pop!(B[j][:p], vertex)
        pop!(B[j][:d], cut)
        JuMP.delete(model, cut) # delete one-by-one is already fast, so we don't bother reoptimizing
        JuMP.optimize!(model); JuMP.assert_is_solved_and_feasible(model; allow_local = false, dual = true)
    end; @info "Lagrangian bound is $(JuMP.objective_bound(model)) after condensing"
end; function restrict_a_frac_block!(B, model, inn)
    œá = solve_restricted_primal(B)
    j = find_a_frac_block(œá)
    if j == 0
        @info "‚ñ∂‚ñ∂‚ñ∂ Now all fractional solutions has become integer"
        return true # you need to stop
    else
        @info "‚ñ∂ eliminating fractionality in block $j"
    end
    mj = inn[j] # the block that we want to make üå≥ branching decision
    ‚ÖÅ = ƒ±.(get_full_vec(œá[j])) # the concatenated fractional trial solution 
    v = get_full_vec(mj) # create a vec of decisions aligning with it
    o = JuMP.@variable(mj) # temporary epi-variable
    c1 = JuMP.@constraint(mj, v - ‚ÖÅ .‚â§ o) 
    c2 = JuMP.@constraint(mj, ‚ÖÅ - v .‚â§ o) # vector of constrs
    JuMP.@objective(mj, Min, o) # set-and-solve routine
    JuMP.optimize!(mj); JuMP.assert_is_solved_and_feasible(mj; allow_local = false) # the small MIP
    iv = get_full_num_tuple(mj) # integer-feasible vertex in NamedTuple format
    JuMP.delete.(mj, c1);
    JuMP.delete.(mj, c2);
    JuMP.delete(mj, o);
    iA = get_bool_part_vec(iv); # the Bool Anchor vector
    JuMP.fix.(get_bool_part_vec(mj), iA; force = true) # üå≥ The branching (= fixing) decision
    for (cut, vertex) = collect(B[j][:d])
        get_bool_part_vec(vertex) == iA && continue # keep the compatible ones previously gened
        pop!(B[j][:p], vertex)
        pop!(B[j][:d], cut)
        JuMP.delete(model, cut)
    end
    return false # don't need to stop
end; 

begin # Data acquisition (D)
    seed = 6787495924352825842 # [interesting case] IP_OPT_VALUE > LAG_DUAL_BOUND, but diving can recover IP_OPT_VALUE!
    # seed = rand(Int);
    Random.seed!(seed);
    T = 24; # global
    MarketPrice = [2, 1, 1, 1, 1, 1, 3, 5, 6, 7, 8, 9, 9, 8, 8, 9, 10, 11, 9, 6, 5, 3, 2, 2];
    P_AGR = 47; # pAgr should be in [0, P_AGR]
    D = Vector{Vector{NamedTuple}}(undef, 0); # the global data
    ID = 0; # each house has a unique ID
    while ID < 4 # build house pairs
        ID += 1; h1 = gen_a_G_house(ID)
        ID += 1; h2 = gen_a_D_house(ID, 10)
        push!(D, NamedTuple[h1, h2])
    end
    while ID < 6 # build house singles
        ID += 1; h = gen_a_D_house(ID, 10)
        push!(D, NamedTuple[h])
    end
    J = length(D)
    @info "a community with $J blocks and $ID houses have been built"
end;

if true # üü™ centralized formulation: use primitive device constraints involving private data
    Œß = Vector{NamedTuple}(undef, J) # record the full standard optimal solution
    model = JuMP.Model(() -> Gurobi.Optimizer(GRB_ENV)) # monolithic
    JuMP.set_attribute(model, "MIPGap", 0)
    JuMP.set_attribute(model, "MIPGapAbs", 0)
    for (j, block) = enumerate(D) # add intrablock constraints
        if length(block) == 2
            h1, h2 = block # decode
            # EV's part
            bLent = JuMP.@variable(model, [1:T], Bin) # 0 is lending
            pLent = JuMP.@variable(model, [1:T])
            JuMP.@constraint(model, [t = 1:T], pLent[t] ‚â§ (1 - bLent[t])h1[:P_EV][end])
            JuMP.@constraint(model, [t = 1:T], (1 - bLent[t])h1[:P_EV][begin] ‚â§ pLent[t])
            bEV = JuMP.@variable(model, [1:T, 1:2], Bin)
            pEV = JuMP.@variable(model, [1:T, 1:2])
            JuMP.@constraint(model, [t = 1:T, h = 1:2], pEV[t, h] ‚â§ bEV[t, h]block[h][:P_EV][end])
            JuMP.@constraint(model, [t = 1:T, h = 1:2], bEV[t, h]block[h][:P_EV][begin] ‚â§ pEV[t, h])
            JuMP.@constraint(model, [t = 1:T, h = 1:2], bEV[t, h] ‚â§ bLent[t])
            JuMP.@constraint(model, sum(        view(pEV, :, 1)) ‚â• h1[:E_EV])
            JuMP.@constraint(model, sum(pLent + view(pEV, :, 2)) ‚â• h2[:E_EV])
            # DW's part
            bDW = JuMP.@variable(model, [1:T, 1:2], Bin)
            pDW = JuMP.@expression(model, [t = 1:T, h = 1:2], sum(bDW[prev(t, œÜ-1, T), h]P for (œÜ, P) = enumerate(block[h][:DW])))
            JuMP.@constraint(model, [h = 1:2], sum(view(bDW, :, h)) ‚â• true)
            # household balance
            pBus1 = JuMP.@variable(model, [1:T], lower_bound = -h1[:P_BUS], upper_bound = h1[:P_BUS])
            pBus2 = JuMP.@variable(model, [1:T], lower_bound = false,       upper_bound = h2[:P_BUS])
            JuMP.@constraint(model, pBus1 + h1[:G] ‚â• pLent + h1[:D] + view(pEV, :, 1) + view(pDW, :, 1))
            JuMP.@constraint(model, pBus2          ‚â•         h2[:D] + view(pEV, :, 2) + view(pDW, :, 2))
            Œß[j] = (
                pBus1 = pBus1,
                pBus2 = pBus2,
                pLent = pLent,
                pEV = pEV,
                bLent = bLent,
                bEV = bEV,
                bDW = bDW
            )
        elseif length(block) == 1
            h = block[1] # decode
            # EV's part
            bEV = JuMP.@variable(model, [1:T], Bin)
            pEV = JuMP.@variable(model, [1:T])
            JuMP.@constraint(model, [t = 1:T], pEV[t] ‚â§ bEV[t]h[:P_EV][end])
            JuMP.@constraint(model, [t = 1:T], bEV[t]h[:P_EV][begin] ‚â§ pEV[t])
            JuMP.@constraint(model, sum(pEV) ‚â• h[:E_EV])
            # DW's part
            bDW = JuMP.@variable(model, [1:T], Bin)
            pDW = JuMP.@expression(model, [t = 1:T], sum(bDW[prev(t, œÜ-1, T)]P for (œÜ, P) = enumerate(h[:DW])))
            JuMP.@constraint(model, sum(bDW) ‚â• true)
            # household balance
            pBus = JuMP.@variable(model, [1:T], lower_bound = false, upper_bound = h[:P_BUS])
            JuMP.@constraint(model, pBus ‚â• h[:D] + pEV + pDW)
            Œß[j] = (
                pBus = pBus,
                pEV = pEV,
                bEV = bEV,
                bDW = bDW
            )
        end
    end # we opt not to create an explicit public variable
    JuMP.@expression(model, pAgr, sum(haskey(Œß[j], :pBus) ? Œß[j][:pBus] : Œß[j][:pBus1]+Œß[j][:pBus2] for j = 1:J));
    JuMP.@constraint(model, pAgr .‚â§ P_AGR); # üü° linking constr
    # ‚ö†Ô∏è we do not explicitly enforce the "no reverse flow" constraint, but will test it post-optimize
    JuMP.@objective(model, Min, MarketPrice ‚ãÖ pAgr);
    JuMP.optimize!(model); JuMP.assert_is_solved_and_feasible(model; allow_local = false)
    all(ƒ±.(pAgr) .> 0) || error("This instance is not proper, please enlarge load")
    an_UB = JuMP.objective_value(model) + 500
end; # Note: use this standard procedure to pick seed leading to proper tests

inn = initialize_inn(D); 
my_lock = Threads.ReentrantLock();
model, Œ∏, Œ≤ = initialize_out(an_UB); # a concise outer model
B = [(p = Dict{NamedTuple, JuMP.ConstraintRef}(), d = Dict{JuMP.ConstraintRef, NamedTuple}()) for j = 1:J]; # a vec of Bijections::NamedTuple
out_upd_vec = falses(J);
parallel_CG!(B, model, Œ∏, Œ≤); # ‚ö†Ô∏èüî¥ [deprecate] condense!(B, model)
# Note: at this line we had derived a typically tight Lagrangian bound

# Note: The following 2 methods are both primal heuristics, hence cannot guarantee optimality, even feasibility!
solve_restricted_primal(B; mip = true); # 1Ô∏è‚É£ This is a handy integer-feasible solution (typically good-quality)
while true # 2Ô∏è‚É£ the diving heuristic to recover another integer-feasible solution (dive only once here)
    restrict_a_frac_block!(B, model, inn) && break
    parallel_CG!(B, model, Œ∏, Œ≤);
end
