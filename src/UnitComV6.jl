# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # 
import LinearAlgebra
import Distributions
import Statistics
import MosekTools
import Polyhedra
import Random
import Gurobi
import JuMP
using Logging

# T = 4 test okay
# 26/11/24

GRB_ENV = Gurobi.Env()
macro optimise() return esc(:((_, status) = (JuMP.optimize!(Ã¸), JuMP.termination_status(Ã¸)))) end
ip(x, y) = LinearAlgebra.dot(x, y)
norm1(x) = LinearAlgebra.norm(x, 1)
LT(P, c, x) = P \ (x .+ c) # from STD to Desired ğŸ’¡ x can be both Vector and Matrix
function get_Pc(yM::Matrix)
    N, S = size(yM)
    Ã¸ = JumpModel(1) # ğŸŒ¸ MOSEK
    JuMP.@variable(Ã¸, P[1:N, 1:N])
    JuMP.@variable(Ã¸, c[1:N])
    JuMP.@variable(Ã¸, L[i = 1:N, j = 1:i]) # SparseAxisArray
    JuMP.@variable(Ã¸, v[1:N])
    JuMP.@variable(Ã¸, ae[1:S, 1:N]) # ancillary variable: abs(entry)
    JuMP.@expression(Ã¸, e[s = 1:S, i = 1:N], ip(P[i, :], yM[:, s]) - c[i])
    JuMP.@expression(Ã¸, Lmat, [(j > i ? 0. * L[i, i] : 1. * L[i, j]) for i in 1:N, j in 1:N])
    JuMP.@expression(Ã¸, LDiagmat, [(j == i ? 1. * L[i, i] : 0. * L[i, i]) for i in 1:N, j in 1:N])
    JuMP.@constraint(Ã¸, [s = 1:S], sum(ae[s, :]) <= 1.) # the ||â‹…||â‚ <= 1 constraint
    JuMP.@constraint(Ã¸, [s = 1:S, i = 1:N],  e[s, i] <= ae[s, i])    
    JuMP.@constraint(Ã¸, [s = 1:S, i = 1:N], -e[s, i] <= ae[s, i])    
    JuMP.@constraint(Ã¸, [i = 1:N], [v[i], 1., L[i, i]] in JuMP.MOI.ExponentialCone()) # exp(v) <= L
    JuMP.@constraint(Ã¸, [P Lmat; transpose(Lmat) LDiagmat] in JuMP.PSDCone())
    JuMP.@objective(Ã¸, Max, sum(v))
    @optimise()
    if status != JuMP.OPTIMAL
        error(" $status ")
    end
    return P, c = JuMP.value.(P), JuMP.value.(c)
end
function is_in(y, yM)
    N, S = size(yM)
    Ã¸ = JumpModel(0)
    JuMP.@variable(Ã¸, c[1:S] >= 0.)
    JuMP.@constraint(Ã¸, sum(c) == 1.)
    JuMP.@constraint(Ã¸, [i = 1:N], y[i] == ip(yM[i, :], c))
    @optimise()
    status == JuMP.OPTIMAL && return JuMP.value.(c)
    error(" in is_in: status = $status")
end
ds(ref, y) = LinearAlgebra.norm(ref .- y, 1)
ds(ref, y::Matrix) = [ds(ref, v) for v in eachcol(y)]
ds(y::Matrix, ::Any) = error(" malfunction ")
function ptsD0(N) return [zeros(N) one(ones(N, N))] end
function pts2N(N)
    a, b = LinearAlgebra.Diagonal(ones(N)), LinearAlgebra.Diagonal(-ones(N))
    [(c % 2 == 0) ? b[i, div(c, 2)] : a[i, div(c+1, 2)] for i in 1:N, c in 1:2N]
end
vov2m(vec) = [vec[c][r] for r in eachindex(vec[1]), c in eachindex(vec)]
m2vov(mat) = [Vector(c) for c in eachcol(mat)]
@enum State begin t1; t2f; t3; t2b end
(Î”Î² = 1.5; Î²nm1V = 0.0 : Î”Î² : 5e3) # hyper-param
function JumpModel(i)
    if i == 0 
        Ã¸ = JuMP.Model(() -> Gurobi.Optimizer(GRB_ENV))
        # JuMP.set_attribute(Ã¸, "QCPDual", 1)
        # vio = JuMP.get_attribute(Ã¸, Gurobi.ModelAttribute("MaxVio")) ğŸ€ we suggest trial-and-error to decide if a constr is tight, rather than using this cmd
    elseif i == 1 
        Ã¸ = JuMP.Model(MosekTools.Optimizer)
    elseif i == 2 
        Ã¸ = JuMP.direct_model(Gurobi.Optimizer(GRB_ENV))
    end
    JuMP.set_silent(Ã¸) # JuMP.unset_silent(Ã¸)
    return Ã¸
    # (_, status) = (JuMP.optimize!(Ã¸), JuMP.termination_status(Ã¸))
    # if status != JuMP.OPTIMAL
    #     if status == JuMP.INFEASIBLE_OR_UNBOUNDED
    #         JuMP.set_attribute(Ã¸, "DualReductions", 0)
    #         (_, status) = (JuMP.optimize!(Ã¸), JuMP.termination_status(Ã¸))
    #     end
    #     if status == JuMP.DUAL_INFEASIBLE
    #         @info "The program is unbounded"
    #         error()
    #     else
    #         error(" $status ")
    #     end
    # else
    #     return worstObj, worstZ = JuMP.objective_value(Ã¸), JuMP.value.(Z)
    # end
end
macro stage_1_code()
    return esc(:(
        begin
            JuMP.@variable(Ã¸, u[t = 1:T, g = 1:G+1], Bin)
            JuMP.@variable(Ã¸, v[t = 1:T, g = 1:G+1], Bin)
            JuMP.@variable(Ã¸, x[t = 1:T, g = 1:G+1], Bin)
            JuMP.@constraint(Ã¸, [g = 1:G+1],          x[1, g] - ZS[g]     == u[1, g] - v[1, g])
            JuMP.@constraint(Ã¸, [t = 2:T, g = 1:G+1], x[t, g] - x[t-1, g] == u[t, g] - v[t, g])
            JuMP.@expression(Ã¸, o1, sum(CST[g] * u[t, g] + CSH[g] * v[t, g] for t in 1:T, g in 1:G+1))
        end
    ))
end
macro f_prim_code()
    return esc(:(
        begin
            JuMP.@variable(Ã¸, p[t = 1:T, g = 1:G+1])       
            JuMP.@variable(Ã¸, Ï±[t = 1:T, g = 1:G] >= 0.) # G+1 @ Ï±sl
            JuMP.@variable(Ã¸, Ï–[t = 1:T, w = 1:W] >= 0.)
            JuMP.@variable(Ã¸, Î¶[t = 1:T, l = 1:L] >= 0.)
            JuMP.@expression(Ã¸, Ï±sl[t = 1:T], sum(Î¶[t, :]) - sum(Ï–[t, :]) - sum(Ï±[t, g] for g in 1:G)) # ğŸ€ in place of Ï±[t, G+1]
            JuMP.@constraint(Ã¸, DÏ±l[t = 1:T], Ï±sl[t] >= 0.) # ğŸ€
            JuMP.@constraint(Ã¸, DÏ±u[t = 1:T], p[t, G+1] - Ï±sl[t] >= 0.) # ğŸ€
            JuMP.@constraint(Ã¸, Dvp[t = 1:T, w = 1:W], Y[t, w] >= Ï–[t, w]) 
            JuMP.@constraint(Ã¸, Dzt[t = 1:T, l = 1:L], Z[t, l] >= Î¶[t, l])
            JuMP.@constraint(Ã¸, Dvr[t = 1:T, g = 1:G], p[t, g] >= Ï±[t, g])
            JuMP.@constraint(Ã¸, Dpi[t = 1:T, g = 1:G+1], p[t, g] >= PI[g] * x[t, g])
            JuMP.@constraint(Ã¸, Dps[t = 1:T, g = 1:G+1], PS[g] * x[t, g] >= p[t, g])
            JuMP.@constraint(Ã¸, Dd1[g = 1:G+1], p[1, g] - ZP[g] >= -RC)             # ğŸ€
            JuMP.@constraint(Ã¸, Du1[g = 1:G+1], RC >= p[1, g] - ZP[g])              # ğŸ€
            JuMP.@constraint(Ã¸, Dd[t = 2:T, g = 1:G+1], p[t, g] - p[t-1, g] >= -RC) # ğŸ€
            JuMP.@constraint(Ã¸, Du[t = 2:T, g = 1:G+1], RC >= p[t, g] - p[t-1, g])  # ğŸ€
            JuMP.@expression(Ã¸, bf[t = 1:T, b = 1:B],
                sum(FM[b, NG[g]] * Ï±[t, g] for g in 1:G)
                + sum(FM[b, NW[w]] * Ï–[t, w] for w in 1:W)
                - sum(FM[b, NL[l]] * Î¶[t, l] for l in 1:L)
            )
            JuMP.@constraint(Ã¸, Dbl[t = 1:T, b = 1:B], bf[t, b] >= -BC[b])
            JuMP.@constraint(Ã¸, Dbr[t = 1:T, b = 1:B], BC[b] >= bf[t, b])
            JuMP.@expression(Ã¸, lscost_2, -ip(CL, Î¶))
            JuMP.@expression(Ã¸, gccost_1, sum(CG[g]   * (p[t, g]   - Ï±[t, g]) for t in 1:T, g in 1:G))
            JuMP.@expression(Ã¸, gccost_2, sum(CG[G+1] * (p[t, G+1] - Ï±sl[t])  for t in 1:T))
            JuMP.@expression(Ã¸, gencost, sum(C1[g] * p[t, g] for t in 1:T, g in 1:G+1))
            JuMP.@expression(Ã¸, primobj, lscost_2 + gccost_1 + gccost_2 + gencost)
        end
    ))
end
macro f_dual_code()
    return esc(:(
        begin
            JuMP.@variable(Ã¸, DÏ±l[t = 1:T] >= 0.)
            JuMP.@variable(Ã¸, DÏ±u[t = 1:T] >= 0.)
            JuMP.@variable(Ã¸, Dvp[t = 1:T, w = 1:W] >= 0.)
            JuMP.@variable(Ã¸, Dzt[t = 1:T, l = 1:L] >= 0.)
            JuMP.@variable(Ã¸, Dvr[t = 1:T, g = 1:G] >= 0.)
            JuMP.@variable(Ã¸, Dpi[t = 1:T, g = 1:G+1] >= 0.)
            JuMP.@variable(Ã¸, Dps[t = 1:T, g = 1:G+1] >= 0.)
            JuMP.@variable(Ã¸, Dd1[g = 1:G+1] >= 0.)
            JuMP.@variable(Ã¸, Du1[g = 1:G+1] >= 0.)
            JuMP.@variable(Ã¸, Dd[t = 2:T, g = 1:G+1] >= 0.)
            JuMP.@variable(Ã¸, Du[t = 2:T, g = 1:G+1] >= 0.)
            JuMP.@variable(Ã¸, Dbl[t = 1:T, b = 1:B] >= 0.)
            JuMP.@variable(Ã¸, Dbr[t = 1:T, b = 1:B] >= 0.)
            JuMP.@constraint(Ã¸, p1[g = 1:G], CG[g] + C1[g] + Dps[1, g] - Dpi[1, g] - Dvr[1, g] + Du1[g] - Dd1[g] + Dd[1+1, g] - Du[1+1, g] == 0.) # ğŸ€
            JuMP.@constraint(Ã¸, p2[t = 2:T-1, g = 1:G], CG[g] + C1[g] + Dps[t, g] - Dpi[t, g] - Dvr[t, g] + Du[t, g] - Dd[t, g] + Dd[t+1, g] - Du[t+1, g] == 0.) # ğŸ€
            JuMP.@constraint(Ã¸, pT[g = 1:G], CG[g] + C1[g] + Dps[T, g] - Dpi[T, g] - Dvr[T, g] + Du[T, g] - Dd[T, g] == 0.) # ğŸ€
            JuMP.@constraint(Ã¸, psl1, CG[G+1] + C1[G+1] + Dps[1, G+1] - Dpi[1, G+1] - DÏ±u[1] + Du1[G+1] - Dd1[G+1] + Dd[1+1, G+1] - Du[1+1, G+1] == 0.) # ğŸ€slack
            JuMP.@constraint(Ã¸, psl2[t = 2:T-1], CG[G+1] + C1[G+1] + Dps[t, G+1] - Dpi[t, G+1] - DÏ±u[t] + Du[t, G+1] - Dd[t, G+1] + Dd[t+1, G+1] - Du[t+1, G+1] == 0.) # ğŸ€slack
            JuMP.@constraint(Ã¸, pslT, CG[G+1] + C1[G+1] + Dps[T, G+1] - Dpi[T, G+1] - DÏ±u[T] + Du[T, G+1] - Dd[T, G+1] == 0.) # ğŸ€slack
            JuMP.@constraint(Ã¸, Ï±[t = 1:T, g = 1:G], -CG[g] + Dvr[t, g] + CG[G+1] - (DÏ±u[t] - DÏ±l[t]) + sum(FM[b, NG[g]] * (Dbr[t, b] - Dbl[t, b]) for b in 1:B) >= 0.)
            JuMP.@constraint(Ã¸, Ï–[t = 1:T, w = 1:W], Dvp[t, w] + CG[G+1] - (DÏ±u[t] - DÏ±l[t]) + sum(FM[b, NW[w]] * (Dbr[t, b] - Dbl[t, b]) for b in 1:B) >= 0.)
            JuMP.@constraint(Ã¸, Î¶[t = 1:T, l = 1:L], -CL[t, l] + Dzt[t, l] - CG[G+1] + DÏ±u[t] - DÏ±l[t] - sum(FM[b, NL[l]] * (Dbr[t, b] - Dbl[t, b]) for b in 1:B) >= 0.)
            JuMP.@expression(Ã¸, dualobj, -ip(Y, Dvp) - ip(Z, Dzt) + ip(Dd1 .- Du1, ZP)
                - RC * (sum(Dd1) + sum(Du1) + sum(Dd) + sum(Du))
                + sum((PI[g] * Dpi[t, g] - PS[g] * Dps[t, g]) * x[t, g] for t in 1:T, g in 1:G+1)
                - sum(BC[b] * (Dbl[t, b] + Dbr[t, b]) for t in 1:T, b in 1:B)
            )
        end
    ))
end
function load_UC_data(T)
    CST = [0.72, 0.60, 0.63]/5;
    CSH = [0.15, 0.15, 0.15]/5;
    @assert T in 1:8
    CL = [8.0 6.888 7.221; 8.0 6.888 7.221; 8.0 6.888 7.221; 8.0 6.888 7.221; 8.0 6.888 7.221; 8.0 6.888 7.221; 8.0 6.888 7.221; 16.0 13.776 14.443]/5;
    CL = CL[end-T+1:end, :]
    CG = [3.6, 3.4, 4.0]/5;
    C1 = [0.67, 0.41, 0.93]/5;
    PI = [0.45, 0.375, 0.5];
    PS = [5.5,  4,     4.5];
    LM = [4, 3.5, 3];
    ZS = [0, 0, 1.0]; # Binary
    ZP = [0, 0, 0.5];
    NG = [3, 2] # ğŸ€ since `G+1` generator is on the slack bus, it doesn't contribute to any power flow, we omit it
    NW = [2, 3]
    NL = [4, 5, 6]
    FM = let
        [0.0 -0.44078818231301325 -0.3777905547603966 -0.2799660317280192 -0.29542103345397086 -0.3797533556433226; 0.0 -0.32937180203296385 -0.3066763814017814 -0.5368505424397501 -0.27700207451336545 -0.30738349678665927; 0.0 -0.229840015654023 -0.3155330638378219 -0.18318342583223077 -0.42757689203266364 -0.31286314757001815; 0.0 0.06057464187751593 -0.354492865935812 0.018549141862024054 -0.10590781852459258 -0.20249230420747694; 0.0 0.3216443011699881 0.23423126113776493 -0.3527138586915366 0.11993854023522055 0.23695476674932447; 0.0 0.10902536164428178 -0.020830957469362865 0.03338570129374399 -0.19061834882900958 -0.016785057525005476; 0.0 0.0679675129952012 -0.23669799249298656 0.02081298380774932 -0.11883340633558914 -0.39743076066016436; 0.0 0.06529291323070335 0.270224001096538 0.019993968970548615 -0.11415717519819152 0.1491923753527435; 0.0 -0.004718271353187364 0.3752831329676507 -0.001444827108524449 0.00824935667359894 -0.35168467956022; 0.0 -0.007727500862975828 -0.07244512026401648 0.11043559886871346 -0.15706353427814482 -0.0704287300373348; 0.0 -0.06324924164201379 -0.13858514047466358 -0.019368156699224842 0.11058404966199031 -0.2508845597796152]
    end
    BC = 2.0 * [1.0043, 2.191, 1.3047, 0.6604, 1.7162, 0.6789, 1.0538, 1.1525, 1.3338, 0.4969, 0.7816]
    RC = 1.7 # ramping cap
    return CST, CSH, CL, CG, C1, PI, PS, LM, ZS, ZP, NG, NW, NL, FM, BC, RC
end

T, G, W, L, B = 4, 2, 2, 3, 11 # ğŸŒ¸ G+1 is the size of (u, v, x)
CST, CSH, CL, CG, C1, PI, PS, LM, ZS, ZP, NG, NW, NL, FM, BC, RC = load_UC_data(T)

begin # build (MY, yM)
    N = T * W
    Random.seed!(23)
    â„™ = let
        â„™ = Distributions.Uniform(0.05, 0.5)
        lb = rand(â„™, N)
        â„™ = Distributions.Uniform(3.3, 3.8)
        ub = rand(â„™, N)
        Distributions.Product(Distributions.Uniform.(lb, ub)) # if you use other underlying distributions, they maybe inefficient to sample, i.e., many many time before you can sample an enclosing y
    end
    MY = Statistics.mean(â„™)
    y_peripheral, dist_y_peri = let # collect a set of points that encloses MY in all directions
        a = [[2 for _ in 1:N]; N];
        y_peripheral = NaN * ones(a...);
        a = [2 for _ in 1:N];
        dist_y_peri = -Inf * ones(a...);
        y_peripheral, dist_y_peri
    end;
    for b in 1:150
        for s in 1:2^N
            y = rand(â„™)
            Î” = y .- MY
            a, d = (Î” .> 0) .+ 1, norm1(Î”)
            if d > dist_y_peri[a...]
                y_peripheral[a..., :] .= y
                dist_y_peri[a...] = d
            end
        end
        mi, ma = minimum(dist_y_peri), maximum(dist_y_peri)
        print("b = $b, min_dist = $mi, MAX_dist = $ma  \r")
    end
    @assert all(-Inf .< [minimum(dist_y_peri), maximum(dist_y_peri)])
    y_peripheral = Matrix(transpose(reshape(y_peripheral, (:, N))));
    yM_ref, yM_eft, yM_ineft = let
        P, c = get_Pc(y_peripheral)
        @assert all(LinearAlgebra.eigen(P).values .> 0) " invalid transform P "
        yM_ref = LT(P, c, pts2N(N)); # ğŸ’¡ extreme points
        @assert all( sum(yM_ref .< 0; dims = 2) .== ones(N) ) " abnormal yM_ref "
        yM_eft = yM_ref[:, [(c % 2 == 1) for c in 1:2N]] # valid points
        yM_ineft = yM_ref[:, [(c % 2 == 0) for c in 1:2N]] # for invalid negatives
        yM_ref, yM_eft, yM_ineft
    end
    y = rand(â„™)
    min_dist = ds(y, yM_ineft)
    yM_delegate = vov2m([y for _ in eachindex(min_dist)])
    for b in 1:10000
        for s in 1:5000
            y = rand(â„™)
            _, c = findmin(y)
            d = ds(y, yM_ineft[:, c])
            if d < min_dist[c]
                yM_delegate[:, c] .= y
                min_dist[c] = d
            end
        end
        print("b = $b, sumdist = $(sum(min_dist)) \r")
    end
    yM_center = let
        p = [yM_ineft[i, i] / (yM_ineft[i, i] - yM_delegate[i, i]) for i in 1:N]
        cm = vov2m([p[i] * yM_delegate[:, i] + (1 - p[i]) * yM_ineft[:, i] for i in 1:N])
        cm[one(ones(Bool, (N, N)))] .= 0 # to round small floating point errors
        cm
    end
    yM = [yM_eft yM_center] # a trial
    yM = let
        v = Polyhedra.vrep(m2vov(yM));
        v_rmed = Polyhedra.removevredundancy(v, Gurobi.Optimizer) # ğŸ’¡ this procedure is efficient
        vov2m(v_rmed.points)
    end
    is_in(MY, yM) # ğŸŒ¸ you must test
    @assert Polyhedra.ininterior(MY, Polyhedra.polyhedron(Polyhedra.vrep(m2vov(yM)))) # ğŸŒ¸ test if possible
    # Polyhedra.volume(poly)
    # h = Polyhedra.hrep(poly)
end
Yvec2mat(vec) = reshape(vec, (T, W))
MY, yM = Yvec2mat(MY), cat([Matrix(Yvec2mat(v)) for v in eachcol(yM)]..., dims = 3)

Random.seed!(8544002554851888986)
MZ = let
    Dload = Distributions.Arcsine.(LM)
    vec = [rand.(Dload) for t in 1:T]
    [vec[t][l] for t in 1:T, l in 1:L]
end

u, v, x, Y, Z, x1, x2, Î²1, Î²2 = let
    u, v, x = 1. * rand(Bool, T, G+1), 1. * rand(Bool, T, G+1), 1. * rand(Bool, T, G+1)
    x1 = u, v, x
    Î²1, Y = rand(T, W), rand(T, W)
    x2 = x1, Y
    Î²2, Z = rand(T, L), rand(T, L)
    u, v, x, Y, Z, x1, x2, Î²1, Î²2
end
Î”1, Î”2, â„¶1, â„¶2, â„¶u = let
    â„¶u = Dict( # surrogate \underline_{h} (SP_lb_surrogate)
        "cn" => Float64[],
        "px" => typeof(x1)[]
    ) # each element cut is generated at (x_trial, Q_trial, P_trial)
    â„¶1 = Dict( 
        "st" => Bool[],
        "x" =>  typeof(x1)[],
        "rv" => Int[],
        "cn" => Float64[],
        "px" => typeof(x1)[],
        "pÎ²" => typeof(Î²1)[]
    )
    â„¶2 = Dict(
        "st" => Bool[],
        "x" =>  typeof(x2)[],
        "rv" => typeof(Z)[],
        "cn" => Float64[],
        "px" => typeof(x2)[],
        "pÎ²" => typeof(Î²2)[]
    )
    Î”1 = Dict(
        "f" => Float64[],
        "x" => typeof(x1)[],
        "Î²" => typeof(Î²1)[]
    )
    Î”2 = Dict(
        "f" => Float64[],
        "x" => typeof(x2)[],
        "Î²" => typeof(Î²2)[]
    )
    Î”1, Î”2, â„¶1, â„¶2, â„¶u
end
function pushCut(D, x, rv, cn, px, pÎ²) return (push!(D["st"], true); push!(D["x"], x); push!(D["rv"], rv); push!(D["cn"], cn); push!(D["px"], px); push!(D["pÎ²"], pÎ²)) end
function pushSimplicial(D, f, x, Î²) return (push!(D["f"], f); push!(D["x"], x); push!(D["Î²"], Î²)) end
function readCut(â„¶)
    cnV2, pxV2, pÎ²V2, stV2 = â„¶["cn"], â„¶["px"], â„¶["pÎ²"], â„¶["st"]
    R2 = length(cnV2)
    return R2, stV2, cnV2, pxV2, pÎ²V2
end
function readSimplicial(Î”)
    fV, xV, Î²V = Î”["f"], Î”["x"], Î”["Î²"]
    R2 = length(fV)
    return R2, fV, xV, Î²V
end
macro master_o2_o3()
    return esc(quote
        JuMP.@variable(Ã¸, o2)
        JuMP.@constraint(Ã¸, o2 >= ip(MY, Î²1))
        JuMP.@variable(Ã¸, o3)
        for r in 1:R2
            stV2[r] && JuMP.@constraint(Ã¸, o3 >= cnV2[r] + ip(px1V2[r], (u, v, x)) + ip(pÎ²1V2[r], Î²1))
        end
    end)
end
macro master_get_ret()
    return esc(quote
        lb, x1, Î²1, cost1plus2, o3 = let
            lb = JuMP.objective_value(Ã¸)
            x1 = JuMP.value.(u), JuMP.value.(v), JuMP.value.(x)
            Î²1 = JuMP.value.(Î²1)
            cost1plus2 = JuMP.value(o1) + JuMP.value(o2)
            o3 = JuMP.value(o3)
            lb, x1, Î²1, cost1plus2, o3
        end
    end)
end
macro add_beta_nm1Bnd(b) # invoked in master() and psi()
    return esc(quote
        (bind = iCnt[1]; Î²normBnd = Î²nm1V[bind])
        bind == length(Î²nm1V) && error(" enlarge the scale of Î²nm1V please. ")
        JuMP.@variable(Ã¸, aÎ²[eachindex(eachrow($b)), eachindex(eachcol($b))])
        JuMP.@constraint(Ã¸, aÎ² .>=  $b)
        JuMP.@constraint(Ã¸, aÎ² .>= -$b)
        JuMP.@constraint(Ã¸, sum(aÎ²) <= Î²normBnd)
    end)
end
function master(masterIsMature, iCnt, R2, stV2, cnV2, px1V2, pÎ²1V2) # enforcing boundedness version
    Ã¸ = JumpModel(0)
    @stage_1_code()
    JuMP.@variable(Ã¸, Î²1[t = 1:T, w = 1:W])
    @add_beta_nm1Bnd(Î²1)
    @master_o2_o3()
    JuMP.@objective(Ã¸, Min, o1 + o2 + o3)
    @optimise()
    @assert status == JuMP.OPTIMAL " in master1(), $status "
    @master_get_ret()
    (norm1(Î²1) > Î²normBnd - Î”Î²/3) ? (iCnt[1] += 1) : (masterIsMature[1] = true)
    return lb, x1, Î²1, cost1plus2, o3
end
function master(R2, stV2, cnV2, px1V2, pÎ²1V2) # final version
    Ã¸ = JumpModel(0)
    @stage_1_code()
    JuMP.@variable(Ã¸, Î²1[t = 1:T, w = 1:W])
    @master_o2_o3()
    JuMP.@objective(Ã¸, Min, o1 + o2 + o3)
    @optimise()
    @assert status == JuMP.OPTIMAL " in masterFinal(), $status "
    @master_get_ret()
    return lb, x1, Î²1, cost1plus2, o3
end
function master(masterIsMature, iCnt, â„¶1) # portal
    R2, stV2, cnV2, px1V2, pÎ²1V2 = readCut(â„¶1)
    if masterIsMature[1]
        lb, x1, Î²1, cost1plus2, o3 = master(R2, stV2, cnV2, px1V2, pÎ²1V2) # 3ï¸âƒ£
        return true, lb, x1, Î²1, cost1plus2, o3
    else
        if R2 >= 1
            lb, x1, Î²1, cost1plus2, o3 = master(masterIsMature, iCnt, R2, stV2, cnV2, px1V2, pÎ²1V2) # 2ï¸âƒ£
            return false, lb, x1, Î²1, cost1plus2, o3
        else
            x1, Î²1 = master() # 1ï¸âƒ£
            return false, -Inf, x1, Î²1, NaN, -Inf
        end
    end
end
function master() # initialization version
    Ã¸ = JumpModel(0)
    @stage_1_code()
    JuMP.@variable(Ã¸, -Î”Î² <= Î²1[t = 1:T, w = 1:W] <= Î”Î²)
    JuMP.@objective(Ã¸, Min, o1 + ip(MY, Î²1))
    @optimise()
    @assert status == JuMP.OPTIMAL " in master(), $status "
    x1 = JuMP.value.(u), JuMP.value.(v), JuMP.value.(x)
    Î²1 = JuMP.value.(Î²1)
    return x1, Î²1
end
function psi(iCnt, x1, Y) # t2f, 
    x2 = x1, Y # ğŸ€ this is fixed
    R2, _, cnV2, px2V2, pÎ²2V2 = readCut(â„¶2)
    Ã¸ = JumpModel(0)
    JuMP.@variable(Ã¸, Î²2[t = 1:T, l = 1:L])
    @add_beta_nm1Bnd(Î²2)
    if R2 == 0
        JuMP.@objective(Ã¸, Min, ip(MZ, Î²2))
    else
        JuMP.@variable(Ã¸, o2)
        JuMP.@constraint(Ã¸, [r = 1:R2], o2 >= cnV2[r] + ip(px2V2[r], x2) + ip(pÎ²2V2[r], Î²2))
        JuMP.@objective(Ã¸, Min, ip(MZ, Î²2) + o2)
    end
    @optimise()
    @assert status == JuMP.OPTIMAL " in psi(): $status "
    Î²2 = JuMP.value.(Î²2)
    let
        bnm = norm1(Î²2)
        if bnm > Î²normBnd - Î”Î²/3
            iCnt[1] += 1
        elseif bnm < (Î²normBnd - Î”Î²) - Î”Î²/3
            iCnt[1] -= 1
        end
    end
    return x2, Î²2
end
function gen_cut_for_â„¶1(x1, Y) # t2b
    function gen_cut_Ïˆ_wrt_x1(x1Î“, Y)
        R2, _, cnV2, px2V2, pÎ²2V2 = readCut(â„¶2)
        @assert R2 >= 1
        Ã¸ = JumpModel(0)
        JuMP.@variable(Ã¸, x1[i = 1:3, t = 1:T, g = 1:G+1]) # a part of x2
        JuMP.@constraint(Ã¸, cp[i = 1:3, t = 1:T, g = 1:G+1], x1[i, t, g] == x1Î“[i][t, g])
        JuMP.@variable(Ã¸, Î²2[t = 1:T, l = 1:L])
        JuMP.@variable(Ã¸, o2)
        JuMP.@constraint(Ã¸, [r = 1:R2], o2 >= cnV2[r] + ip(px2V2[r], ((x1[1, :, :], x1[2, :, :], x1[3, :, :]), Y)) + ip(pÎ²2V2[r], Î²2))
        JuMP.@objective(Ã¸, Min, ip(MZ, Î²2) + o2)
        @optimise()
        if status != JuMP.OPTIMAL
            if status == JuMP.INFEASIBLE_OR_UNBOUNDED
                JuMP.set_attribute(Ã¸, "DualReductions", 0)
                @optimise()
            end
            status == JuMP.DUAL_INFEASIBLE && return -Inf
            error("in gen_cut_Ïˆ_wrt_x1: $status")
        else
            tmp = JuMP.dual.(cp)
            px1 = tmp[1, :, :], tmp[2, :, :], tmp[3, :, :]
            cn = JuMP.objective_value(Ã¸) - ip(px1, x1Î“)
            return cn, px1
        end
    end
    ret = gen_cut_Ïˆ_wrt_x1(x1, Y)
    if length(ret) == 1
        return ret
    else
        cn, px1 = ret
        pÎ²1 = -Y # ğŸ’¡ this is fixed, and irrespective of 'Î²1'
        return cn, px1, pÎ²1
    end
end
function maximize_Ï†2_over_Z(x2, Î²2)
    (u, v, x), Y = x2
    Ã¸ = JumpModel(2)
    JuMP.@variable(Ã¸, 0. <= Z[t = 1:T, l = 1:L] <= LM[l])
    JuMP.@expression(Ã¸, f_cn, ip(CL, Z))
    @f_dual_code()
    JuMP.@objective(Ã¸, Max, -ip(Î²2, Z) + f_cn + dualobj)
    # JuMP.unset_silent(Ã¸)
    @optimise()
    @assert status == JuMP.OPTIMAL " in maximize_Ï†2_over_Z: $status "
    return JuMP.value.(Z)
end
function eval_prim(u, v, x, Y, Z)
    Ã¸ = JumpModel(2)
    @f_prim_code()
    JuMP.@objective(Ã¸, Min, primobj)
    @optimise()
    @assert status == JuMP.OPTIMAL " in eval_prim: $status "
    return JuMP.value(primobj)
end
function eval_dual(u, v, x, Y, Z)
    Ã¸ = JumpModel(2)
    @f_dual_code()
    JuMP.@objective(Ã¸, Max, dualobj)
    @optimise()
    @assert status == JuMP.OPTIMAL " in eval_dual: $status "
    return JuMP.value(dualobj)
end
function eval_Ï†2(x2, Î²2, Z)
    (u, v, x), Y = x2
    primobj, dualobj = eval_prim(u, v, x, Y, Z), eval_dual(u, v, x, Y, Z)
    @assert primobj + 5e-6 >= dualobj "weak dual $dualobj, $primobj"
    @assert dualobj + 9e-6 >= primobj "strong dual $dualobj, $primobj"
    return Ï†2 = -ip(Î²2, Z) + ip(CL, Z) + primobj
end
function gen_cut_for_â„¶2(x2, Z)
    function gen_cut_f_wrt_x2(x2, Z) # this cut is always tight
        Ã¸ = JumpModel(0)
        JuMP.@variable(Ã¸, u[t = 1:T, g = 1:G+1])
        JuMP.@variable(Ã¸, v[t = 1:T, g = 1:G+1])
        JuMP.@variable(Ã¸, x[t = 1:T, g = 1:G+1])
        JuMP.@variable(Ã¸, Y[t = 1:T, w = 1:W])
        JuMP.@constraint(Ã¸, cpu[t = 1:T, g = 1:G+1], u[t, g] == x2[1][1][t, g])
        JuMP.@constraint(Ã¸, cpv[t = 1:T, g = 1:G+1], v[t, g] == x2[1][2][t, g])
        JuMP.@constraint(Ã¸, cpx[t = 1:T, g = 1:G+1], x[t, g] == x2[1][3][t, g])
        JuMP.@constraint(Ã¸, cpY[t = 1:T, w = 1:W], Y[t, w] == x2[2][t, w])
        @f_prim_code()
        JuMP.@objective(Ã¸, Min, primobj) # ğŸ€ only the 2nd half of obj(f(x1, Y, Z))
        @optimise()
        @assert status == JuMP.OPTIMAL "in gen_cut_f_wrt_x2(): $status"
        px1 = JuMP.dual.(cpu), JuMP.dual.(cpv), JuMP.dual.(cpx)
        pY  = JuMP.dual.(cpY)
        px2 = px1, pY
        cn = JuMP.objective_value(Ã¸) - ip(px2, x2)
        cn += ip(CL, Z) # ğŸ€ an additional const obj term of f(x1, Y, Z)
        return cn, px2
    end
    cn, px2 = gen_cut_f_wrt_x2(x2, Z)
    pÎ²2 = -Z # ğŸ’¡ this is fixed, and irrespective of 'Î²2'
    return cn, px2, pÎ²2
end
function eval_Î”_at(Î”, x, Î²) # t1, in termination criterion
    isempty(Î”["f"]) && return Inf
    R2, fV, xV, Î²V = readSimplicial(Î”)
    Ã¸ = JumpModel(0)
    JuMP.@variable(Ã¸, Î»[1:R2] >= 0.)
    JuMP.@constraint(Ã¸, sum(Î») == 1.)
    JuMP.@constraint(Ã¸, [i = 1:3, t = 1:T, g = 1:G+1], sum(xV[r][i][t, g] * Î»[r] for r in 1:R2) == x[i][t, g])
    JuMP.@constraint(Ã¸, [t = 1:T, w = 1:W],            sum(Î²V[r][t, w]    * Î»[r] for r in 1:R2) ==    Î²[t, w])
    JuMP.@objective(Ã¸, Min, ip(fV, Î»))
    @optimise()
    if status != JuMP.OPTIMAL
        if status == JuMP.INFEASIBLE_OR_UNBOUNDED
            JuMP.set_attribute(Ã¸, "DualReductions", 0)
            @optimise()
        end
        status == JuMP.INFEASIBLE && return Inf
        error(" in eval_Î”_at(): $status ")
    end
    return JuMP.objective_value(Ã¸)
end
function eval_Ï†1ub(x1, Î²1, yM) # t2: a max-min problem to choose worst Y
    function eval_xby(x1, Î²1, Y)
        R2, fV, x2V, Î²2V = readSimplicial(Î”2)
        @assert R2 >= 1
        const_obj = -ip(Î²1, Y)
        Ã¸ = JumpModel(0)
        JuMP.@variable(Ã¸, Î»[1:R2] >= 0.)
        JuMP.@constraint(Ã¸, sum(Î») == 1.)
        JuMP.@variable(Ã¸, Î²2[t = 1:T, l = 1:L])
        JuMP.@constraint(Ã¸, [t = 1:T, l = 1:L],            sum(Î²2V[r][t, l]       * Î»[r] for r in 1:R2) ==    Î²2[t, l])
        # following 2 lines are minimum infeas. system ########################################################
        JuMP.@constraint(Ã¸, [i = 1:3, t = 1:T, g = 1:G+1], sum(x2V[r][1][i][t, g] * Î»[r] for r in 1:R2) == x1[i][t, g])
        JuMP.@constraint(Ã¸, [t = 1:T, w = 1:W],            sum(x2V[r][2][t, w]    * Î»[r] for r in 1:R2) ==     Y[t, w])
        #######################################################################################################
        JuMP.@objective(Ã¸, Min, ip(MZ, Î²2) + ip(fV, Î»)) # problem \bar{Ïˆ}(x1, Y)
        @optimise()
        if status != JuMP.OPTIMAL
            if status == JuMP.INFEASIBLE_OR_UNBOUNDED
                JuMP.set_attribute(Ã¸, "DualReductions", 0)
                @optimise()
            end
            status == JuMP.INFEASIBLE && return Inf
            error(" in eval_xby(), status = $status ")
        end
        return const_obj + JuMP.objective_value(Ã¸)
    end
    if isempty(Î”2["f"]) # only once
        return (Ï†1ub, index) = (Inf, 1)
    end
    NY = size(yM, 3)
    fullVec = zeros(NY)
    for i in 1:NY
        Ï†1x1b1y = eval_xby(x1, Î²1, yM[:, :, i])
        if Ï†1x1b1y == Inf
            return (Ï†1ub, index) = (Inf, i)
        else
            fullVec[i] = Ï†1x1b1y
        end
    end
    return (Ï†1ub, index) = findmax(fullVec)
end

masterCnt, psiCnt = [2], [2]
masterIsMature = falses(1)
x1V, Î²1V, x2V, Î²2V, ZV = let
    x1V, Î²1V = [x1], [Î²1]
    x2V, Î²2V = [x2], [Î²2] # ğŸ’¡ (x1, Î²1) -> Y -> Î²2 is essential; 'x2' is NOT essential
    ZV = [Z]
    x1V, Î²1V, x2V, Î²2V, ZV
end
tV, termination_flag = [t1], falses(1)
while true
    ST = tV[1]
    if ST == t1
        vldt, lb, x1, Î²1, cost1plus2, _ = master(masterIsMature, masterCnt, â„¶1)
        let
            Ï†1ub = eval_Î”_at(Î”1, x1, Î²1)
            ub = cost1plus2 + Ï†1ub # ğŸ€ ub(Î”1) is a valid upper bound of Ï…_MSDRO
            gap = abs(ub - lb) / max( abs(lb), abs(ub) )
            @info " t1: masterCnt[$(masterCnt[1])] ($vldt)lb = $lb | $ub = ub, gap = $gap"
            if gap < 0.0001
                @info " ğŸ˜Š gap < 0.01%, thus terminate "
                termination_flag[1] = true
            end
        end
        x1V[1], Î²1V[1] = x1, Î²1
        tV[1] = t2f
    elseif ST == t2f
            x1, Î²1 = x1V[1], Î²1V[1]
            _, index = eval_Ï†1ub(x1, Î²1, yM)
        x2, Î²2 = psi(psiCnt, x1, yM[:, :, index]) # 2ï¸âƒ£ only a trial (x2, Î²2) is needed here
        x2V[1], Î²2V[1] = x2, Î²2
        tV[1] = t3
    elseif ST == t3
        x2, Î²2 = x2V[1], Î²2V[1]
        ZV[1] = Z = maximize_Ï†2_over_Z(x2, Î²2) # ğŸŒ¸ the ğŸ¾ bottleneck
        termination_flag[1] && break # ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿
        Ï†2 = eval_Ï†2(x2, Î²2, Z) # ğŸŒ¸ strong duality confirmation inside
        cn, px2, pÎ²2 = gen_cut_for_â„¶2(x2, Z)
        pushSimplicial(Î”2, Ï†2, x2, Î²2) # âœ… Î”2 is a precise evaluation of Ï†2(x2, Î²2)
        pushCut(â„¶2, x2, Z, cn, px2, pÎ²2) # âœ… â„¶2 is a valid underestimator of    Ï†2(x2, Î²2)
        tV[1] = t2b
    elseif ST == t2b
            x1, Î²1 = x1V[1], Î²1V[1]
            Ï†1ub, index = eval_Ï†1ub(x1, Î²1, yM)
        ret = gen_cut_for_â„¶1(x1, yM[:, :, index])
        if length(ret) == 1
            tV[1] = t2f
        else
            pushCut(â„¶1, x1, index, ret...) # âœ… â„¶1(â„¶2) is a valid underestimator of Ï†1(x1, Î²1)
            Ï†1ub < Inf && pushSimplicial(Î”1, Ï†1ub, x1, Î²1) # âš ï¸ conditional update âœ… Î”1(Î”2) is a valid overestimator of Ï†1(x1, Î²1)
            tV[1] = t1
        end
    end
end


